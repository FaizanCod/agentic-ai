{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOn+MlGqgiPjKqHbqDOrjLg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silent-doom/agentic-ai/blob/feature%2Feditor-agent/Faizan_Editor_agent_v1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cWqUltkABXy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "import sys\n",
        "import subprocess\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 0. LIGHTWEIGHT SETUP (No MediaPipe/TensorFlow)\n",
        "# =================================================================\n",
        "\n",
        "def install_lightweight_dependencies():\n",
        "    \"\"\"Installs only the necessary, stable libraries.\"\"\"\n",
        "    try:\n",
        "        import moviepy\n",
        "        import yt_dlp\n",
        "        import whisper\n",
        "    except ImportError:\n",
        "        print(\"üì¶ Installing lightweight dependencies...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "            \"moviepy==1.0.3\", \"yt-dlp\", \"git+https://github.com/openai/whisper.git\"])\n",
        "\n",
        "        # System deps for MoviePy\n",
        "        subprocess.run(\"apt update -qq && apt install -qq imagemagick\", shell=True, check=False)\n",
        "        subprocess.run(\"sed -i 's/none/read,write/' /etc/ImageMagick-6/policy.xml\", shell=True, check=False)\n",
        "\n",
        "install_lightweight_dependencies()"
      ],
      "metadata": {
        "id": "kt6aAStYAM2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import cv2\n",
        "import numpy as np\n",
        "import yt_dlp\n",
        "import whisper\n",
        "from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip\n",
        "from moviepy.video.fx.all import crop\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24n6-dTHwOP9",
        "outputId": "ebe73698-662c-4d97-9457-e03d988a1461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  match = re.search('\\d+$', rotation_line)\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 1. CONFIGURATION & ROBUST PATH DISCOVERY\n",
        "# =================================================================\n",
        "\n",
        "def get_robust_paths():\n",
        "    \"\"\"\n",
        "    Attempts to locate the AI_Transcripts folder across different mount points.\n",
        "    Returns (TRANSCRIPT_FOLDER, INPUT_PLAN_FILE, OUTPUT_FOLDER)\n",
        "    \"\"\"\n",
        "    # Standard Colab mount point is /content/drive/My Drive\n",
        "    # POC mount point used previously was /content/gdrive/MyDrive\n",
        "    possible_bases = [\n",
        "        \"/content/drive/My Drive/AI_Transcripts\",\n",
        "        \"/content/gdrive/MyDrive/AI_Transcripts\",\n",
        "        \"/content/gdrive/My Drive/AI_Transcripts\",\n",
        "        \"/content/drive/MyDrive/AI_Transcripts\"\n",
        "    ]\n",
        "\n",
        "    for base in possible_bases:\n",
        "        if os.path.exists(base):\n",
        "            # Force a refresh of the directory listing (fixes Colab stale file issues)\n",
        "            os.listdir(base)\n",
        "            plan_file = os.path.join(base, 'viral_clip_plan.json')\n",
        "            if os.path.exists(plan_file):\n",
        "                print(f\"‚úÖ Found planning data at: {base}\")\n",
        "                return base, plan_file, os.path.join(base, 'final_shorts')\n",
        "\n",
        "    # Default fallback if nothing is found (creates standard path)\n",
        "    default_base = \"/content/drive/My Drive/AI_Transcripts\"\n",
        "    return default_base, os.path.join(default_base, 'viral_clip_plan.json'), os.path.join(default_base, 'final_shorts')\n",
        "\n",
        "\n",
        "# Haar Cascade for Face Detection (Standard Computer Vision model)\n",
        "HAAR_URL = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
        "HAAR_PATH = \"/content/haarcascade_frontalface_default.xml\"\n",
        "\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "# Replace with the video used in Phase 1 if not dynamically loaded\n",
        "YOUTUBE_URL = \"https://www.youtube.com/watch?v=Rni7Fz7208c\""
      ],
      "metadata": {
        "id": "MjWKp87QxkFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 2. UTILITY: SEGMENT DOWNLOAD\n",
        "# =================================================================\n",
        "\n",
        "def _parse_time_to_seconds(time_str):\n",
        "    h, m, s = map(int, time_str.split(':'))\n",
        "    return h * 3600 + m * 60 + s\n",
        "\n",
        "def download_segment(url, start_time, end_time, output_path):\n",
        "    \"\"\"Downloads partial video segment using yt-dlp.\"\"\"\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"‚úÖ Segment exists: {output_path}\")\n",
        "        return output_path\n",
        "\n",
        "    print(f\"‚¨áÔ∏è Downloading segment: {start_time} - {end_time}...\")\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',\n",
        "        'outtmpl': output_path,\n",
        "        'quiet': True,\n",
        "        'download_ranges': lambda _, __: [{'start_time': _parse_time_to_seconds(start_time), 'end_time': _parse_time_to_seconds(end_time)}],\n",
        "        'force_keyframes_at_cuts': True,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "        return output_path\n",
        "    except Exception as e:\n",
        "        print(f\"üî¥ Download error: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ff9BOjl6yXYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 3. LIGHTWEIGHT FACE TRACKING (OpenCV Haar)\n",
        "# =================================================================\n",
        "\n",
        "def setup_face_detector():\n",
        "    \"\"\"Downloads the Haar Cascade XML if missing.\"\"\"\n",
        "    if not os.path.exists(HAAR_PATH):\n",
        "        print(\"üì• Downloading Face Detection Model (Haar Cascade)...\")\n",
        "        urllib.request.urlretrieve(HAAR_URL, HAAR_PATH)\n",
        "    return cv2.CascadeClassifier(HAAR_PATH)\n",
        "\n",
        "def detect_face_x_center(frame, face_cascade):\n",
        "    \"\"\"Detects face center using OpenCV (No Tensorflow needed).\"\"\"\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "    if len(faces) == 0:\n",
        "        return None\n",
        "\n",
        "    # Pick the largest face\n",
        "    largest_face = max(faces, key=lambda f: f[2] * f[3]) # width * height\n",
        "    x, y, w, h = largest_face\n",
        "\n",
        "    center_x = x + (w / 2)\n",
        "    return center_x / frame.shape[1] # Return relative X (0.0 - 1.0)\n",
        "\n",
        "def vertical_crop_smart(clip):\n",
        "    \"\"\"Crops 16:9 to 9:16 keeping the speaker centered using OpenCV.\"\"\"\n",
        "    print(\"ü§ñ Tracking face for smart crop (OpenCV)...\")\n",
        "\n",
        "    face_cascade = setup_face_detector()\n",
        "    face_x_positions = []\n",
        "\n",
        "    # Analyze 1 frame per second\n",
        "    duration = int(clip.duration)\n",
        "    if duration == 0: duration = 1\n",
        "\n",
        "    for t in range(0, duration):\n",
        "        try:\n",
        "            # Get frame at time t\n",
        "            frame = clip.get_frame(t)\n",
        "            # detect_face_x_center expects BGR or RGB?\n",
        "            # MoviePy returns RGB. OpenCV Cascade works on Gray, so conversion handled inside.\n",
        "            x_pos = detect_face_x_center(frame, face_cascade)\n",
        "            if x_pos: face_x_positions.append(x_pos)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Calculate average position\n",
        "    avg_x = sum(face_x_positions) / len(face_x_positions) if face_x_positions else 0.5\n",
        "    print(f\"‚úÖ Center detected at relative X: {avg_x:.2f}\")\n",
        "\n",
        "    w, h = clip.size\n",
        "    target_ratio = 9 / 16\n",
        "    new_width = h * target_ratio\n",
        "\n",
        "    center_pixel = avg_x * w\n",
        "    x1 = int(center_pixel - (new_width / 2))\n",
        "\n",
        "    # Clamp bounds\n",
        "    if x1 < 0: x1 = 0\n",
        "    if x1 + new_width > w: x1 = w - new_width\n",
        "\n",
        "    cropped = crop(clip, x1=x1, y1=0, width=int(new_width), height=h)\n",
        "    return cropped.resize(height=1920)"
      ],
      "metadata": {
        "id": "C33weODVyiOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 4. CAPTIONING\n",
        "# =================================================================\n",
        "\n",
        "def generate_dynamic_captions(video_clip, raw_audio_path):\n",
        "    \"\"\"Generates Whisper-based word-level captions.\"\"\"\n",
        "    print(\"üìù Generating captions...\")\n",
        "    video_clip.audio.write_audiofile(raw_audio_path, logger=None)\n",
        "\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(raw_audio_path, word_timestamps=True)\n",
        "\n",
        "    caption_clips = []\n",
        "\n",
        "    for segment in result['segments']:\n",
        "        for word in segment.get('words', []):\n",
        "            txt = word['word'].strip()\n",
        "            start, end = word['start'], word['end']\n",
        "            duration = end - start\n",
        "            if duration < 0.1: duration = 0.1\n",
        "\n",
        "            # Simple Karaoke Style\n",
        "            txt_clip = (TextClip(txt, fontsize=85, color='yellow', font='Arial-Bold', stroke_color='black', stroke_width=3)\n",
        "                        .set_position(('center', 0.8), relative=True)\n",
        "                        .set_start(start)\n",
        "                        .set_duration(duration))\n",
        "            caption_clips.append(txt_clip)\n",
        "\n",
        "    return caption_clips"
      ],
      "metadata": {
        "id": "XNNkOmpkymJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 5. MAIN RUNNER\n",
        "# =================================================================\n",
        "\n",
        "def run_editor_agent():\n",
        "    # Attempt to mount drive if not already visible\n",
        "    if not os.path.exists(\"/content/drive\"):\n",
        "        print(\"Mounting Google Drive...\")\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "    # Locate files\n",
        "    TRANSCRIPT_FOLDER, INPUT_PLAN_FILE, OUTPUT_FOLDER = get_robust_paths()\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(INPUT_PLAN_FILE):\n",
        "        print(f\"üî¥ Error: Plan file NOT found at any expected location.\")\n",
        "        print(f\"Checked: {INPUT_PLAN_FILE}\")\n",
        "        print(\"Debugging: Current /content/drive contents:\")\n",
        "        os.system(\"ls -R /content/drive/My\\ Drive | grep AI_Transcripts -A 5\")\n",
        "        return\n",
        "\n",
        "    with open(INPUT_PLAN_FILE, 'r') as f:\n",
        "        plan_data = json.load(f)\n",
        "\n",
        "    clips = plan_data.get('viral_clips', [])\n",
        "    print(f\"üé¨ Processing {len(clips)} clips...\")\n",
        "\n",
        "    for i, clip in enumerate(clips):\n",
        "        clip_id = clip.get('clip_id', i+1)\n",
        "        clean_title = re.sub(r'[^a-zA-Z0-9]', '', clip['viral_hook'][:15])\n",
        "\n",
        "        print(f\"\\n--- Clip {clip_id}: {clip['viral_hook']} ---\")\n",
        "\n",
        "        temp_vid = f\"/content/temp_{clip_id}.mp4\"\n",
        "        temp_aud = f\"/content/temp_{clip_id}.wav\"\n",
        "        final_path = os.path.join(OUTPUT_FOLDER, f\"Short_{clip_id}_{clean_title}.mp4\")\n",
        "\n",
        "        # 1. Download Partial Segment\n",
        "        seg_path = download_segment(YOUTUBE_URL, clip['start_time'], clip['end_time'], temp_vid)\n",
        "        if not seg_path: continue\n",
        "\n",
        "        try:\n",
        "            # 2. Edit\n",
        "            raw = VideoFileClip(seg_path)\n",
        "            vertical = vertical_crop_smart(raw)\n",
        "            captions = generate_dynamic_captions(vertical, temp_aud)\n",
        "\n",
        "            # 3. Render\n",
        "            final = CompositeVideoClip([vertical] + captions)\n",
        "            print(f\"üíæ Rendering: {final_path}\")\n",
        "            # Use 'medium' preset for speed, threads for multi-core processing\n",
        "            final.write_videofile(final_path, codec='libx264', audio_codec='aac', fps=24, preset='medium', threads=4, logger=None)\n",
        "            print(\"‚úÖ Done.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"üî¥ Error: {e}\")\n",
        "        finally:\n",
        "            if os.path.exists(temp_vid): os.remove(temp_vid)\n",
        "            if os.path.exists(temp_aud): os.remove(temp_aud)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_editor_agent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QfdONnRyo6M",
        "outputId": "9d5e2a7b-0534-449c-9991-6057bcc40380"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:<>:19: SyntaxWarning: invalid escape sequence '\\ '\n",
            "\n",
            "WARNING:py.warnings:<>:19: SyntaxWarning: invalid escape sequence '\\ '\n",
            "\n",
            "WARNING:py.warnings:/tmp/ipython-input-377540170.py:19: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  os.system(\"ls -R /content/drive/My\\ Drive | grep AI_Transcripts -A 5\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "‚úÖ Found planning data at: /content/drive/My Drive/AI_Transcripts\n",
            "üé¨ Processing 5 clips...\n",
            "\n",
            "--- Clip 1: Old Twitter was extremely far left; I am restoring balance now. ---\n",
            "‚¨áÔ∏è Downloading segment: 00:05:00 - 00:06:05...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: [youtube] No supported JavaScript runtime could be found. Only deno is enabled by default; to use another runtime add  --js-runtimes RUNTIME[:PATH]  to your command/config. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one\n",
            "WARNING: [youtube] Rni7Fz7208c: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "WARNING: [youtube] Rni7Fz7208c: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñ Tracking face for smart crop (OpenCV)...\n",
            "üì• Downloading Face Detection Model (Haar Cascade)...\n",
            "‚úÖ Center detected at relative X: 0.54\n",
            "üìù Generating captions...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139M/139M [00:01<00:00, 106MiB/s]\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Rendering: /content/drive/My Drive/AI_Transcripts/final_shorts/Short_1_OldTwitterwas.mp4\n",
            "‚úÖ Done.\n",
            "\n",
            "--- Clip 2: Stop the brain rot: Social media optimizes for dopamine addiction. ---\n",
            "‚¨áÔ∏è Downloading segment: 00:08:00 - 00:09:00...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: [youtube] No supported JavaScript runtime could be found. Only deno is enabled by default; to use another runtime add  --js-runtimes RUNTIME[:PATH]  to your command/config. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one\n",
            "WARNING: [youtube] Rni7Fz7208c: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "WARNING: [youtube] Rni7Fz7208c: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Tracking face for smart crop (OpenCV)...\n",
            "‚úÖ Center detected at relative X: 0.54\n",
            "üìù Generating captions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Rendering: /content/drive/My Drive/AI_Transcripts/final_shorts/Short_2_Stopthebrain.mp4\n",
            "‚úÖ Done.\n",
            "\n",
            "--- Clip 3: Working will be optional, like a hobby, in less than 20 years. ---\n",
            "‚¨áÔ∏è Downloading segment: 00:32:40 - 00:33:45...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] No supported JavaScript runtime could be found. Only deno is enabled by default; to use another runtime add  --js-runtimes RUNTIME[:PATH]  to your command/config. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one\n",
            "WARNING: [youtube] Rni7Fz7208c: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "WARNING: [youtube] Rni7Fz7208c: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Tracking face for smart crop (OpenCV)...\n",
            "‚úÖ Center detected at relative X: 0.56\n",
            "üìù Generating captions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Rendering: /content/drive/My Drive/AI_Transcripts/final_shorts/Short_3_Workingwillbe.mp4\n",
            "‚úÖ Done.\n",
            "\n",
            "--- Clip 4: AI is the ONLY solution for the massive US debt crisis. ---\n",
            "‚¨áÔ∏è Downloading segment: 00:46:30 - 00:47:30...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] No supported JavaScript runtime could be found. Only deno is enabled by default; to use another runtime add  --js-runtimes RUNTIME[:PATH]  to your command/config. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one\n",
            "WARNING: [youtube] Rni7Fz7208c: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "WARNING: [youtube] Rni7Fz7208c: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Tracking face for smart crop (OpenCV)...\n",
            "‚úÖ Center detected at relative X: 0.44\n",
            "üìù Generating captions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Rendering: /content/drive/My Drive/AI_Transcripts/final_shorts/Short_4_AIistheONLY.mp4\n",
            "‚úÖ Done.\n",
            "\n",
            "--- Clip 5: Based on video game progress, we are probably in a simulation. ---\n",
            "‚¨áÔ∏è Downloading segment: 00:52:08 - 00:53:05...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] No supported JavaScript runtime could be found. Only deno is enabled by default; to use another runtime add  --js-runtimes RUNTIME[:PATH]  to your command/config. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one\n",
            "WARNING: [youtube] Rni7Fz7208c: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "WARNING: [youtube] Rni7Fz7208c: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Tracking face for smart crop (OpenCV)...\n",
            "‚úÖ Center detected at relative X: 0.47\n",
            "üìù Generating captions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Rendering: /content/drive/My Drive/AI_Transcripts/final_shorts/Short_5_Basedonvideo.mp4\n",
            "‚úÖ Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m6CFIbpxyzp1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}