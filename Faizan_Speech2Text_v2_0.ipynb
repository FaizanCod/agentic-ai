{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaizanCod/agentic-ai/blob/master/Faizan_Speech2Text_v2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q yt-dlp\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q youtube-transcript-api # NEW: Library for fast caption extraction\n",
        "!pip install -q torch torchaudio ffmpeg-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQHyaIcsDQBr",
        "outputId": "af17961a-d3d5-4b75-e141-7e62ee83990d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/180.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m174.1/180.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/3.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m485.1/485.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import yt_dlp\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import sys\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "id": "BJ8UwSHUAvMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "YOUTUBE_URL = \"https://www.youtube.com/watch?v=gC88zq9Y4gQ\"  # <-- REPLACE with your video URL\n",
        "OUTPUT_DIR = \"/content/transcription_output/\"\n",
        "AUDIO_FILE = os.path.join(OUTPUT_DIR, \"audio.mp3\")\n",
        "JSON_OUTPUT_FILE_NAME = \"video_analysis.json\"\n",
        "JSON_OUTPUT_FILE_PATH = os.path.join(OUTPUT_DIR, JSON_OUTPUT_FILE_NAME)"
      ],
      "metadata": {
        "id": "Q6hJdmnyC4qi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- GEMINI AGENT SETUP ---\n",
        "# Note: In a Colab environment, you typically need to set the API_KEY environment variable\n",
        "# manually or rely on the host environment's configuration.\n",
        "# For simplicity, we use the standard setup assuming requests will handle the key if available.\n",
        "API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent\"\n",
        "API_KEY = \"AIzaSyCwWhwTK_a84BvvpvB602m__IJxx76yB5M\""
      ],
      "metadata": {
        "id": "GlgUQjuEC7Mi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# AGENT TOOL 1: UTILITIES\n",
        "# =================================================================\n",
        "\n",
        "def install_dependencies():\n",
        "    \"\"\"Installs required Python packages quietly.\"\"\"\n",
        "    print(\"--- Installing Dependencies ---\")\n",
        "    try:\n",
        "        os.system('pip install -q yt-dlp')\n",
        "        os.system('pip install -q git+https://github.com/openai/whisper.git')\n",
        "        os.system('pip install -q youtube-transcript-api')\n",
        "        os.system('pip install -q torch torchaudio ffmpeg-python')\n",
        "    except Exception as e:\n",
        "        print(f\"Error during installation: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "def get_video_id(url):\n",
        "    \"\"\"Extracts the YouTube video ID from a given URL.\"\"\"\n",
        "    match = re.search(r\"(?<=v=)[a-zA-Z0-9_-]{11}|(?<=youtu\\.be/)[a-zA-Z0-9_-]{11}|(?<=/embed/)[a-zA-Z0-9_-]{11}\", url)\n",
        "    return match.group(0) if match else None\n",
        "\n",
        "def format_time(seconds):\n",
        "    \"\"\"Converts seconds to HH:MM:SS format.\"\"\"\n",
        "    seconds = int(seconds)\n",
        "    hours, remainder = divmod(seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
        "\n",
        "def group_segments_by_context(segments, max_gap_sec=2.0):\n",
        "    \"\"\"\n",
        "    Merges segments into contextually complete blocks based on time gaps.\n",
        "    Returns segments with unified 'start' and 'end' keys.\n",
        "    \"\"\"\n",
        "    if not segments:\n",
        "        return []\n",
        "\n",
        "    grouped_output = []\n",
        "    # Initialize the first group\n",
        "    current_group = {\n",
        "        \"start\": segments[0][\"start\"],\n",
        "        \"text\": segments[0][\"text\"],\n",
        "        \"end\": segments[0][\"end\"]\n",
        "    }\n",
        "\n",
        "    for i in range(1, len(segments)):\n",
        "        prev_end = current_group[\"end\"]\n",
        "        current_start = segments[i][\"start\"]\n",
        "\n",
        "        # If the gap is small, merge the text and extend the end time of the current group\n",
        "        if (current_start - prev_end) < max_gap_sec:\n",
        "            current_group[\"text\"] += \" \" + segments[i][\"text\"]\n",
        "            current_group[\"end\"] = segments[i][\"end\"]\n",
        "        else:\n",
        "            # If the gap is large, finalize the current group and start a new one\n",
        "            grouped_output.append(current_group)\n",
        "            current_group = {\n",
        "                \"start\": current_start,\n",
        "                \"text\": segments[i][\"text\"],\n",
        "                \"end\": segments[i][\"end\"]\n",
        "            }\n",
        "\n",
        "    # Append the last remaining group\n",
        "    grouped_output.append(current_group)\n",
        "    return grouped_output"
      ],
      "metadata": {
        "id": "mM2tFJJtD9WU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# AGENT TOOL 2: TRANSCRIPTION & FALLBACK LOGIC\n",
        "# =================================================================\n",
        "\n",
        "def run_youtube_caption_api(video_id):\n",
        "    \"\"\"Attempts to fetch English captions directly from YouTube.\"\"\"\n",
        "    try:\n",
        "        # 1. Get the list of available transcripts\n",
        "        ytt_api = YouTubeTranscriptApi()\n",
        "\n",
        "        # 2. Find the English transcript (prioritizing manually created over auto-generated)\n",
        "        fetched_transcript = ytt_api.fetch(video_id, languages=['en']).to_raw_data()\n",
        "\n",
        "        raw_api_segments = []\n",
        "        for item in fetched_transcript:\n",
        "            # FIX: Access attributes directly (item.text) instead of dict syntax (item['text'])\n",
        "            # The API returns objects with .text, .start, and .duration attributes\n",
        "            segment = {\n",
        "                \"text\": item['text'],\n",
        "                \"start\": item['start'],\n",
        "                \"end\": item['start'] + item['duration']\n",
        "            }\n",
        "            raw_api_segments.append(segment)\n",
        "\n",
        "        print(\"âœ… Success: Retrieved segments using YouTube Captions API.\")\n",
        "        return raw_api_segments\n",
        "\n",
        "    except (TranscriptsDisabled, NoTranscriptFound) as e:\n",
        "        print(f\"âŒ Fallback needed: Native YouTube captions not found or disabled.\")\n",
        "        return None\n",
        "    except TypeError:\n",
        "        # Fallback for version mismatch where item might be an object, not a dict\n",
        "        # Re-attempting loop assuming object structure if dict access failed\n",
        "        try:\n",
        "            raw_api_segments = []\n",
        "            for item in fetched_transcript:\n",
        "                segment = {\n",
        "                  \"text\": item['text'],\n",
        "                  \"start\": item['start'],\n",
        "                  \"end\": item['start'] + item['duration']\n",
        "                }\n",
        "                raw_api_segments.append(segment)\n",
        "            print(\"âœ… Success: Retrieved segments using YouTube Captions API (Object Mode).\")\n",
        "            return raw_api_segments\n",
        "        except Exception as e:\n",
        "             print(f\"âŒ Fallback needed: Error parsing transcript objects: {e}\")\n",
        "             return None\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Fallback needed: An unexpected API error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "def run_whisper_transcription(audio_file):\n",
        "    \"\"\"Runs local Whisper model transcription on the downloaded audio.\"\"\"\n",
        "    if not os.path.exists(audio_file):\n",
        "        raise FileNotFoundError(f\"Audio file not found at: {audio_file}\")\n",
        "\n",
        "    print(\"Starting Whisper transcription... (This may take several minutes)\")\n",
        "    try:\n",
        "        # Load the base model (fastest). Change to 'medium' or 'large' for higher accuracy.\n",
        "        model = whisper.load_model(\"base\")\n",
        "        print(\"Whisper model loaded successfully.\")\n",
        "\n",
        "        result = model.transcribe(audio_file, verbose=True, word_timestamps=True)\n",
        "\n",
        "        raw_whisper_segments = []\n",
        "        for segment in result['segments']:\n",
        "            raw_whisper_segments.append({\n",
        "                \"start\": segment['start'],\n",
        "                \"end\": segment['end'],\n",
        "                \"text\": segment['text'].strip()\n",
        "            })\n",
        "\n",
        "        print(f\"âœ… Success: Transcribed {len(raw_whisper_segments)} raw segments using Whisper.\")\n",
        "        return raw_whisper_segments\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ğŸ”´ Fatal Error during Whisper Transcription: {e}\")\n",
        "        return None\n",
        "\n",
        "def download_audio_with_yt_dlp(url, final_output_path):\n",
        "    \"\"\"Downloads audio, handles file naming, and ensures the file exists at final_output_path.\"\"\"\n",
        "    print(f\"Downloading audio from {url}...\")\n",
        "\n",
        "    # We use a temporary base name to avoid confusion with existing files\n",
        "    temp_base_name = \"temp_download\"\n",
        "    output_dir = os.path.dirname(final_output_path)\n",
        "    temp_output_template = os.path.join(output_dir, f\"{temp_base_name}.%(ext)s\")\n",
        "\n",
        "    # Define yt-dlp options for audio extraction and conversion\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'outtmpl': temp_output_template,\n",
        "        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}],\n",
        "        'logger': None, 'quiet': True, 'no_warnings': True,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "\n",
        "        # After download, yt-dlp (with ffmpeg) should have created 'temp_download.mp3'\n",
        "        expected_temp_file = os.path.join(output_dir, f\"{temp_base_name}.mp3\")\n",
        "\n",
        "        if os.path.exists(expected_temp_file):\n",
        "            # Rename the temp file to the final desired path (e.g., audio.mp3)\n",
        "            if os.path.exists(final_output_path):\n",
        "                os.remove(final_output_path) # Remove existing file if present\n",
        "            os.rename(expected_temp_file, final_output_path)\n",
        "            print(f\"âœ… Audio downloaded and saved to {final_output_path}.\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"ğŸ”´ Error: Expected audio file {expected_temp_file} not found after download.\")\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        # Check for specific \"Video unavailable\" errors\n",
        "        if \"Video unavailable\" in str(e):\n",
        "            print(f\"ğŸ”´ Error downloading audio: Video unavailable or restricted.\")\n",
        "        else:\n",
        "            print(f\"ğŸ”´ Error downloading audio with yt-dlp: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "ZNiVpB_JECIC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# AGENT TOOL 3: GEMINI SUMMARIZATION AND JSON STRUCTURING\n",
        "# =================================================================\n",
        "\n",
        "def get_ai_json_schema():\n",
        "    \"\"\"Defines the required structured JSON output for the agent.\"\"\"\n",
        "    return {\n",
        "        \"type\": \"ARRAY\",\n",
        "        \"description\": \"A list of contextually grouped video segments with summaries.\",\n",
        "        \"items\": {\n",
        "            \"type\": \"OBJECT\",\n",
        "            \"properties\": {\n",
        "                \"startTime\": {\"type\": \"STRING\", \"description\": \"The exact start time of the segment in HH:MM:SS format.\"},\n",
        "                \"endTime\": {\"type\": \"STRING\", \"description\": \"The exact end time of the segment in HH:MM:SS format.\"},\n",
        "                \"actualContent\": {\"type\": \"STRING\", \"description\": \"The full transcribed content of the segment.\"},\n",
        "                \"summary\": {\"type\": \"STRING\", \"description\": \"A concise, 10-15 word summary of the main topic and context of this segment, ideal for a video title or chapter marker.\"}\n",
        "            },\n",
        "            \"propertyOrdering\": [\"startTime\", \"endTime\", \"actualContent\", \"summary\"]\n",
        "        }\n",
        "    }\n",
        "\n",
        "def summarize_and_structure_transcript(grouped_segments):\n",
        "    \"\"\"\n",
        "    Calls the Gemini API to structure the transcript data and generate summaries,\n",
        "    using exponential backoff for robustness.\n",
        "    \"\"\"\n",
        "    if not grouped_segments:\n",
        "        return []\n",
        "\n",
        "    # Prepare input for the LLM\n",
        "    formatted_input = \"\\n\".join([\n",
        "        f\"Segment {i+1} [Time: {format_time(seg['start'])} to {format_time(seg['end'])}]: {seg['text']}\"\n",
        "        for i, seg in enumerate(grouped_segments)\n",
        "    ])\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are an expert video content analyst. Your task is to review the provided contextually grouped video segments. \"\n",
        "        \"For each segment, you must generate a high-quality, concise summary (max 15 words) suitable for a chapter title. \"\n",
        "        \"Return the output as a single, raw JSON array following the provided schema. Do not include any text outside the JSON array.\"\n",
        "    )\n",
        "\n",
        "    user_query = (\n",
        "        f\"Analyze the following video segments. For each segment, generate a concise summary. \"\n",
        "        f\"The 'startTime', 'endTime', and 'actualContent' fields must be derived directly from the input provided below, \"\n",
        "        f\"formatted as HH:MM:SS. \\n\\nSegments:\\n{formatted_input}\"\n",
        "    )\n",
        "\n",
        "    payload = {\n",
        "        \"contents\": [{\"parts\": [{\"text\": user_query}]}],\n",
        "        \"systemInstruction\": {\"parts\": [{\"text\": system_prompt}]},\n",
        "        \"generationConfig\": {\n",
        "            \"responseMimeType\": \"application/json\",\n",
        "            \"responseSchema\": get_ai_json_schema()\n",
        "        }\n",
        "    }\n",
        "\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            # We use a standard requests call here\n",
        "            response = requests.post(f\"{API_URL}?key={API_KEY}\", headers=headers, data=json.dumps(payload))\n",
        "            response.raise_for_status()\n",
        "\n",
        "            result = response.json()\n",
        "            json_text = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text')\n",
        "\n",
        "            if json_text:\n",
        "                # The LLM's output is the final structured JSON\n",
        "                return json.loads(json_text)\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"API Attempt {attempt + 1} failed: {e}\")\n",
        "            if attempt < 2:\n",
        "                time.sleep(2 ** attempt)\n",
        "            else:\n",
        "                raise Exception(\"ğŸ”´ Failed to get response from Gemini API after multiple retries.\")\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"ğŸ”´ Error: LLM returned malformed JSON. Retrying.\")\n",
        "            if attempt == 2:\n",
        "                raise Exception(\"ğŸ”´ Failed: LLM consistently returned malformed JSON.\")\n",
        "\n",
        "    return []"
      ],
      "metadata": {
        "id": "Lk-3aRMzEG57"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# MAIN EXECUTION BLOCK\n",
        "# =================================================================\n",
        "\n",
        "def main_agent_run():\n",
        "    # 0. Setup Environment\n",
        "    install_dependencies()\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "    video_id = get_video_id(YOUTUBE_URL)\n",
        "\n",
        "    if not video_id:\n",
        "        print(f\"ğŸ”´ Error: Could not extract a valid video ID from the URL: {YOUTUBE_URL}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n--- Starting Video Agent Pipeline for ID: {video_id} ---\")\n",
        "\n",
        "    # 1. ATTEMPT TRANSCRIPTION (Intelligent Fallback)\n",
        "    raw_segments = run_youtube_caption_api(video_id)\n",
        "\n",
        "    if raw_segments is None:\n",
        "        # Fallback triggered: Download and run Whisper\n",
        "        # FIX: Ensure we use the correct final path variable AUDIO_FILE\n",
        "        if download_audio_with_yt_dlp(YOUTUBE_URL, AUDIO_FILE):\n",
        "            raw_segments = run_whisper_transcription(AUDIO_FILE)\n",
        "\n",
        "    if not raw_segments:\n",
        "        print(\"ğŸ”´ Process stopped: No transcript could be generated by either method.\")\n",
        "        return\n",
        "\n",
        "    # 2. LOGICAL GROUPING (Context-Aware Segmentation)\n",
        "    # The grouping logic relies on seconds. We use the raw segments here.\n",
        "    grouped_segments = group_segments_by_context(raw_segments, max_gap_sec=2.5)\n",
        "    print(f\"âœ… Context Grouping Complete: {len(grouped_segments)} logical segments found.\")\n",
        "\n",
        "    # 3. GEMINI AGENT CALL (Summarization and JSON Structuring)\n",
        "    print(\"\\n--- Sending Data to Gemini Agent for Summarization & Structuring ---\")\n",
        "\n",
        "    # FIX: Pass the raw grouped_segments directly to the summarizer.\n",
        "    # The summarizer function expects keys 'start', 'end', 'text' to create the prompt.\n",
        "    final_json_data = summarize_and_structure_transcript(grouped_segments)\n",
        "\n",
        "    # 4. FINAL OUTPUT\n",
        "    if final_json_data:\n",
        "        with open(JSON_OUTPUT_FILE_PATH, 'w', encoding='utf-8') as f:\n",
        "            json.dump(final_json_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        print(\"\\n---------------------------------------------------------\")\n",
        "        print(\"âœ… AGENT SUCCESS: Final JSON Output Generated.\")\n",
        "        print(f\"File saved to: {JSON_OUTPUT_FILE_PATH}\")\n",
        "        print(\"\\n--- JSON Preview ---\")\n",
        "        print(json.dumps(final_json_data, ensure_ascii=False, indent=2))\n",
        "        print(\"---------------------------------------------------------\")\n",
        "    else:\n",
        "        print(\"ğŸ”´ AGENT FAILED: The LLM did not return the final structured data.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_agent_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqRNvdx5ELqt",
        "outputId": "d386db40-66f4-4f19-8b24-5a078e09ef6b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Installing Dependencies ---\n",
            "\n",
            "--- Starting Video Agent Pipeline for ID: gC88zq9Y4gQ ---\n",
            "âœ… Success: Retrieved segments using YouTube Captions API.\n",
            "âœ… Context Grouping Complete: 1 logical segments found.\n",
            "\n",
            "--- Sending Data to Gemini Agent for Summarization & Structuring ---\n",
            "\n",
            "---------------------------------------------------------\n",
            "âœ… AGENT SUCCESS: Final JSON Output Generated.\n",
            "File saved to: /content/transcription_output/video_analysis.json\n",
            "\n",
            "--- JSON Preview ---\n",
            "[\n",
            "  {\n",
            "    \"startTime\": \"00:00:02\",\n",
            "    \"endTime\": \"00:07:29\",\n",
            "    \"actualContent\": \"Pastry is 15th. Has to get one in as well. Is on a better lap, but so is everyone out there. Cenod's having a real tough time of it though. Science finds himself in third. Lock up for Bman. Won't make the corner. Stroll goes fastest. Pastry gets his lap in when he needed it to the barrier for Oliver. Bman skating deep into the runoff. The yellow flag is out. Vstappen goes to second place. Antonelli is now in the drop zone. 30 seconds to go. Alex Alburn slowing the car down into the corner that we were talking about where the yellow flag is out. You can see it there. Now it's been withdrawn. Colinto goes to fifth. Alban now in the DROP ZONE. NEEDS A LAP AND HE TAGS THE WALL. THE MISTAKE FREE run ends for THE FORMULA 1 FIELD. ALBURN in the drop zone. Tried to snake his way through. Got greedy on the throttle and he breaks the front of the car. Hamilton's just behind him on the circuit and has to find an improvement. I think that was him flashing through there. 19th goes to 18th. can't find it. Lewis Hamilton can't find it. Bortalto gets back. Alburn hitting the barrier and out of qualifying. Then it's Antelli. Bortalto. [music] Lewis Hamilton second here last year. And Yuki Cenoda checkered flag is out. Russell goes fastest. Alonso had done so. Stroll and Alonso. Both of them picking to run on the wets. >> And Anteneelli 17th. Yeah. And has to improve. Isn't on a great lap here. So Antonelli who's been flying this weekend is in big danger. >> He is on two personal bests Maxappen. We're continuing with him as he comes across the line. Vappen goes up to second position. Antonelli pits. It is Albanelli Bortletto Cenoda and Lewis Hamilton second last year. Loads of pace around this circuit in the wet conditions is 20th and last. Here is the man from Melbourne, Oscar Pastri across the line. Oscar Pastri is going to be in now for a pressure lap. Lando Norris trying to avoid that. And he goes top. Pastry now having to deliver at the end of Q2. >> He's got time for another lap. He's got fuel for another lap. You'd have thought if THEY'VE GOT THE CALCULATIONS. >> OH MY WORD. FRANCO COLOPINTO at the corner where he dropped it into the wall last year. crucially keeps it out of the barrier and this session stays green. Now Oliver Bman brilliant form recently 2Q3 Pastri trying to find the improvement in the middle sector. This time he's got it. Bman across the line Bman out in the second part of qualifying. It's behind Esban Oon on board with Hulenberg who's skating through the final corners. What a performance they are putting on for us on the streets of Las Vegas. Pastry is making his way through left hand side of your screen. Driver currently in ninth position. Gazzley's in 11th. Colipinto [music] is in 15th. Three drivers out already. Our Stroll, Okon, and Bearman. Yellow flag is out on track. Oscar Pastri continues on and remains in ninth position. George Russell's finding time out there to go fastest once again. One Williams in the barrier earlier on. The other one now P2. Second place for Isaac Hajar extracting the best from that racing balls entry and now Gazzley. How brave does the Frenchman feel into turn 14. Rotates the outpat. Little correction now. Wants to get early on the throttle. Dancing it between the walls as he tries to take it up through the gears and he dreams of taking the car into [music] the top 10 shootout. Gazzley versus Hulkenber. Gazzley gets there [music] with the seventh fastest time. Pastry made it through in 10th position. Gazzley back-to-back races in the top 10 shootout. George Russell fastest and Hulenberg, Stroll, Okon, Bman, and Colinto. The five to four. Piastri is improving on his benchmark, but Norris has put together a flying lap when it matters most. Remember any trip into the barriers now and it would be pole position for Lando Norris. He hits the front of the field. 2 minutes to go. So, he's well positioned in terms of the the time to be last car on the on the circuit. It'll be about 30 seconds. Pastri might be the last car on track. Let's see if he's going to cross the line here with 1 minute 50 still in hand. That'll mean he gets two more flying laps. And I think he will do that fairly nicely. So, Pastry with a [music] great bit of track position if he can now complete a flying lap. Oh, he's backing off. Switching from the wet to the inter appears to have taken the ultimate pace away from the Mercedes man who is round the final corner and he improves to seventh position. Uh signs is on a better lap as well. Max Vstappen leaving nothing out there as he made his way through. >> Yeah, there is just a whole bunch of greens and then Russell has gone purple in that first sector. So, it's all going to be the final lap. >> Vappen is on his final lap right now. Will Pastry get across the line? It's going to be Nip and Tuck. I think he will by two seconds in the end. Who? Pastry is going to sneak through for one more lap. And it's a McLaren shootout. Can anyone get ahead of them for the moment? Checker flag is out. Liam Lawson P3. Max Staffen in fourth. SIGNS IN FIFTH. SIGNS TO THE FRONT OF THE FIELD. WILLIAMS HAVEN'T HAD A pole position since 2014. Carlos signs held it for all of a few seconds. The world champion strikes back and takes provisional pole by 300s of a second. Russell going very quickly and with a handy slipstream of Pierre Gazzley ahead. Norris has the fastest first sector but he's got two cars ahead of him provisionally. Norris is 4/10 up on Pastri who's actually on a similar first sector to the two ahead for Stafen and Science. Norris is knocking this out of the park with this lap so far. Norris trying to save his best until last. Russell squirming all over the road trying to improve. George Russell currently in ninth position coming across the line in P4. Lando Norris crucial breaking zone ahead of the championship leader. Speed disappears. Clip the apex. Then we'll bounce over the curb. WAITING, WAITING, WAITING. AND NEARLY DROPPING IT INTO THE WALL, BUT getting away WITH IT. DID HE HAVE enough time to play with his old teammate and HIS RIVAL FOR THE TITLE AHEAD? LANDO NORRIS ACROSS THE LINE. AND HE'S DONE IT AGAIN. ANOTHER POLE POSITION when it matters FOR LANDO NORRIS WHO'S AT THE front receiving the team applause. And it's a 1479 3/10 of a second ahead of Stappen that has taken Norris back to the front of the field. Oscar Pastri in fifth place on our timing page. >> Yeah. And he's not on a lap now. He's backed off it or made a mistake in the middle sector. So Pastri had the perfect track position, but made a mistake at the end and he's only fifth. This was Sha Llair who will start ninth for Ferrari. That's the reason for the yellow. And that is a fight over track position between Oscar Pastri and one of the racing balls. Orlando Norris will start his 150th Formula 1 Grand Prix from the front and he is on a hot streak at a crucial moment for his Formula 1 career.\",\n",
            "    \"summary\": \"Lando Norris Grabs Pole in Las Vegas Qualifying; Hamilton and Albon Crash Out.\"\n",
            "  }\n",
            "]\n",
            "---------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0HLY9zIGEPIq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}